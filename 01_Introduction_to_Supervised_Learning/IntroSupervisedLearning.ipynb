{"metadata":{"date":1680627836.168828,"filename":"tpIntroductionApprentissageSupervise.rst","kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"title":"Travaux pratiques - Introduction à l’apprentissage supervisé","language_info":{"name":"python","version":"3.9.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n<a id='chap-tpintroductionapprentissagesupervise'></a>","metadata":{},"id":"138104ec"},{"cell_type":"markdown","source":"# Travaux pratiques - Introduction à l’apprentissage supervisé\n\n**L’objectif** de cette première séance de travaux pratiques est de vous faire découvrir les problèmes de classement et les problèmes de régression avec des modèles linéaires et des perceptrons multi-couches (PMC).\n\nRéférences externes utiles :\n\n> - [Documentation NumPy](https://docs.scipy.org/doc/numpy/user/index.html)  \n- [Documentation SciPy](https://docs.scipy.org/doc/scipy/reference/)  \n- [Documentation MatPlotLib](http://matplotlib.org/)  \n- [Site scikit-learn](http://scikit-learn.org/stable/index.html)  \n- [Site langage python](https://www.python.org)  ","metadata":{},"id":"efa9a3c0"},{"cell_type":"markdown","source":"# Note\n\nIl est fortement conseillé d’utiliser Python 3 pour ces travaux pratiques, voir [cette page\nd’installation](http://cedric.cnam.fr/vertigo/Cours/ml/installationScikitLearn.html).\nPython 2 n’est plus maintenu depuis janvier 2020 et scikit-learn a\nabandonné son support depuis sklearn 0.20. Certaines fonctionnalités\nplus récentes pourraient ne pas être disponibles sous Python 2.x.","metadata":{},"id":"569cd824"},{"cell_type":"code","source":"# Import des bibliothèques utiles\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport sklearn","metadata":{"hide-output":false},"execution_count":null,"outputs":[],"id":"f0228502"},{"cell_type":"markdown","source":"## Régression avec modèles linéaires et polynomiaux\n\nPour commencer ce premier TP, nous examinerons un problème simple de\nrégression avec une seule variable prédictive, similaire à celui\nillustré dans le support de cours. À partir d’un ensembles\nd’observations $ \\{(x_1, y_1), (x_2, y_2), \\dots, (x_n, y_n)\\} $,\nl’objectif est de trouver la fonction $ \\hat{f} $ telle que\n$ \\hat{f}(x_i) = y_i $.\n\nPour cet exemple, commençons par générer des données synthétiques. En\npratique, nous n’aurions bien entendu pas à réaliser ce travail : le jeu\nde données est constitué des observations réelles. Notre jeu de données\nd’exemple consiste en une portion de sinusoïde sur laquelle un bruit\ngaussien a été appliqué.","metadata":{},"id":"e9568db2"},{"cell_type":"code","source":"# Fixe l'aléas pour pouvoir reproduire les résultats\nnp.random.seed(0)\n# On tire au hasard 100 points dans l'intervalle [0,2]\nX = 2 * np.random.rand(100, 1)\n# On calcule la valeur de sin(x) pour chaque point, plus un bruit gaussien aléatoire\ny = np.sin(X[:,0]) + 0.15 * np.random.randn(100)","metadata":{"hide-output":false},"execution_count":null,"outputs":[],"id":"fdf6f049"},{"cell_type":"markdown","source":"Nous pouvons visualisation toutes les données générées, qui forment\nnotre matrice d’observation pour ce problème de régression :","metadata":{},"id":"6bdca90a"},{"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nplt.scatter(X, y, s=50)\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$y$\")\nplt.show()","metadata":{"hide-output":false},"execution_count":null,"outputs":[],"id":"b1233755"},{"cell_type":"markdown","source":"Nous générons maintenant un premier découpage entre données d’apprentissage et données de test. Ce découpage est aléatoire et\ns’effectue à l’aide de la fonction [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\nde scikit-learn. Le paramètre `test_size` permet de spécifier le pourcentage du jeu de données qui sera contenu dans le jeu de test.","metadata":{},"id":"2f51b015"},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\nplt.figure(figsize=(8, 6))\nplt.scatter(X_train, y_train, s=50, edgecolors='none', label=\"Exemples d'entraînement\")\nplt.scatter(X_test, y_test, c='none', s=50, edgecolors='blue', label=\"Exemples d'évaluation\")\nplt.legend()\nplt.show()","metadata":{"hide-output":false},"execution_count":null,"outputs":[],"id":"5d9f6f4c"},{"cell_type":"markdown","source":"Nous cherchons d’abord un modèle linéaire pour ce problème de régression. Regardez la classe\n[LinearRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression)\nde scikit-learn (ainsi que [ces explications](http://scikit-learn.org/stable/modules/linear_model.html#ordinary-least-squares)).\nDans le cas présent, scikit-learn va chercher la fonction affine $ f: x \\rightarrow y = ax + b $ en déterminant les paramètres\n$ a $ et $ b $ à l’aide de la méthode des moindres carrés.\n\nLes résultats sont évalués ici à travers le **coefficient de détermination**, qui est le rapport entre la variance expliquée par le\nmodèle et la variance totale (de la variable expliquée), voir [les explications](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html).\n\nCommençons par instancier un modèle de régression linéaire.","metadata":{},"id":"95a4577c"},{"cell_type":"code","source":"from sklearn import linear_model\nreg = linear_model.LinearRegression()","metadata":{"hide-output":false},"execution_count":null,"outputs":[],"id":"7ffe3bdb"},{"cell_type":"markdown","source":"Tous les modèles implémentés dans scikit-learn suivent la même interface et présentent au moins les trois méthodes suivantes :\n\n- `.fit()` permet d’apprendre le modèle en estimant ses paramètres à\n  partir d’un jeu de données,  \n- `.predict()` ou `.transform()` permet d’appliquer le modèle à de\n  nouvelles données,  \n- `.score()` permet d’évaluer le modèle selon un critère prédéfini\n  (taux de bonne classification, coefficient de détermination, etc.)\n  sur un jeu de test.  \n\n\nPar exemple, dans notre cas, la méthode `.fit(X,y)` permet de déterminer les paramètres de la régression linéaire à partir de nos\nobservations `X` et de notre vérité terrain `y`.","metadata":{},"id":"523a62f0"},{"cell_type":"code","source":"# optimisation du modèle: détermination des paramètres de la régression linéaire par la méthode des moindres carrés\nreg.fit(X_train, y_train)","metadata":{"hide-output":false},"execution_count":null,"outputs":[],"id":"377a7ede"},{"cell_type":"markdown","source":"Nous pouvons évaluer à quel point le modèle « colle » aux données à l’aide du coefficient de détermination calculé sur les exemples du jeu\nd’apprentissage :","metadata":{},"id":"96814af6"},{"cell_type":"code","source":"# attention, score() ici ne renvoie pas l'erreur mais la valeur du coefficient de détermination R² !\ncoeff_train = reg.score(X_train, y_train)\nprint(f\"Coefficient de détermination R² en train : {coeff_train:.2f}\")","metadata":{"hide-output":false},"execution_count":null,"outputs":[],"id":"b7aedde4"},{"cell_type":"markdown","source":"## Question:\n\nCalculer le coefficient de détermination R² sur le jeu de test. Que constatez-vous ?","metadata":{},"id":"714c8b09"},{"cell_type":"markdown","source":"## Correction","metadata":{},"id":"1063a5ca"},{"cell_type":"code","source":"coeff_test = reg.score(X_test, y_test)\nprint(f\"Coefficient de détermination R² en test : {coeff_test:.2f}\")","metadata":{"hide-output":false},"execution_count":null,"outputs":[],"id":"1b85d994"},{"cell_type":"markdown","source":"Nous pouvons ensuite, à partir des coefficients qui ont été estimés,\ntracer notre modèle de régression :","metadata":{},"id":"79e09ff3"},{"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nplt.scatter(X_train,y_train, s=50, edgecolors='none', label=\"Exemples d'apprentissage\")\nplt.scatter(X_test,y_test, c='none', s=50, edgecolors='blue', label=\"Exemples d'évaluation\")\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$y$\")\n\nx_min, x_max = plt.xlim()\nnx = 100\nxx = np.linspace(x_min, x_max, nx).reshape(-1,1)\nplt.plot(xx,reg.predict(xx), color='k', label=\"Régression linéaire\")\nplt.title(\"Régression linéaire unidimensionnelle\")\nplt.legend()\nplt.show()","metadata":{"hide-output":false},"execution_count":null,"outputs":[],"id":"90571825"},{"cell_type":"markdown","source":"## Question\n\nCalculez l’erreur quadratique moyenne du modèle sur les données d’apprentissage et ensuite sur les données de test. Vous pouvez\nl’implémenter vous-même à l’aide de NumPy ou bien consulter la [documentation du module\nsklearn.metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics).","metadata":{},"id":"91e7372a"},{"cell_type":"markdown","source":"## Correction","metadata":{},"id":"0d708cc7"},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\ny_pred_train = reg.predict(X_train)\ny_pred_test = reg.predict(X_test)\n\nmse_train = mean_squared_error(y_train, y_pred_train)\nmse_test = mean_squared_error(y_test, y_pred_test)\nprint(f\"MSE = {mse_train:.3f} (train)\")\nprint(f\"MSE = {mse_test:.3f} (test)\")","metadata":{"hide-output":false},"execution_count":null,"outputs":[],"id":"6d51fab9"},{"cell_type":"markdown","source":"### Régression polynomiale\n\nLa régression linéaire est un outil pratique mais quelque peu limité : les relations entre les variables explicatives et la variable à prédire\nsont rarement linéaires en pratique ! Nous pourrions chercher dans une famille paramétrique plus grande, par exemple les polynômes à une seule\nvariable de degré $ d $ : $ P : x \\rightarrow a_0 + a_1 x + a_2 x^2 + \\dots + a_d x^d $.\n\nLa visualisation interactive ci-dessous permet de visualiser les résultats d’une régression polynomiale appliquée sur notre jeu de\ndonnées, de tracer la régression et d’afficher les coefficients de détermination R² en apprentissage et en test.","metadata":{},"id":"94207254"},{"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn import linear_model\nfrom sklearn.pipeline import Pipeline\n\nfrom ipywidgets import interact, fixed\n\n@interact(degree=(0,10,1), show=fixed(True))\ndef polynomial_fit(degree, show=False):\n    pipe = Pipeline([('poly', PolynomialFeatures(degree=degree)),\n                    ('reg', linear_model.LinearRegression())])\n\n    pipe.fit(X_train, y_train)\n    train_score = pipe.score(X_train, y_train)\n    test_score = pipe.score(X_test, y_test)\n\n    if show:\n        plt.figure(figsize=(8, 6))\n        plt.scatter(X_train, y_train, s=50, edgecolors='none', label=\"Exemples d'apprentissage\")\n        plt.scatter(X_test, y_test, c='none', s=50, edgecolors='blue', label=\"Exemples de test\")\n        x_min, x_max = plt.xlim()\n        xx = np.linspace(x_min, x_max, nx).reshape(-1,1)\n        plt.plot(xx,pipe.predict(xx),color='black', label=\"Régression polynomiale\")\n        plt.legend()\n        plt.show()\n\n        print(f\"Coefficient R² (train): {train_score:.3f}\")\n        print(f\"Coefficient R² (test): {test_score:.3f}\")\n    return train_score, test_score","metadata":{"hide-output":false},"execution_count":null,"outputs":[],"id":"c101f8bf"},{"cell_type":"markdown","source":"### Question\n\nQue se passe-t-il lorsque l’on modifie le degré du polynôme ? Quelles observations pouvez-vous faire concernant le sous-apprentissage ? Le sur-apprentissage ?","metadata":{},"id":"42c26115"},{"cell_type":"markdown","source":"### Correction\n\nLorsque le degré du polynôme est faible (0 ou 1), la correspondance entre la courbe réelle et le modèle de régression est mauvaise (score R² faible, voire négatif). Nous sommes en sous-apprentissage: l’erreur d’approximation est élevée car le modèle que l’on choisit (constante ou régression linéaire) est une mauvaise hypothèse par rapport aux données réelles.\n\nLorsque l’on augmente le degré, le coefficient R² se rapproche de 1 sur les exemples d’apprentissage, mais diminue sur les exemples de test. Visuellement, la variance des prédictions augmente: nous sommes en sur-apprentissage. Le modèle dispose de trop de paramètres libres qui viennent « coller » au bruit statistique dans les données, mais cela ne généralise pas sur les exemples de test.","metadata":{},"id":"c92fae29"},{"cell_type":"markdown","source":"### Question\n\n*(pour aller plus loin)* Tracer les courbes du coefficient R² sur le jeu d’apprentissage et sur le jeu de test en fonction du degré du polynôme (entre 1 et 10). Vous\npouvez utiliser la fonction `polynomial_fit` pour ce faire qui renvoie un tuple contenant les deux scores. Que constatez-vous ?","metadata":{},"id":"6db1a9a4"},{"cell_type":"markdown","source":"### Correction","metadata":{},"id":"cefbdb0e"},{"cell_type":"code","source":"degrees = np.arange(1, 11, 1)\ntrain_scores, test_scores = zip(*[polynomial_fit(d, show=False) for d in degrees])\n\nfig = plt.figure(figsize=(8, 6))\nplt.plot(degrees, train_scores, label=\"Train\")\nplt.plot(degrees, test_scores, label=\"Test\")\nplt.xlabel(\"Degré du polynôme\")\nplt.ylabel(\"R²\")\nplt.xlim(1, 10)\nplt.show()","metadata":{"hide-output":false},"execution_count":null,"outputs":[],"id":"1747d8cf"},{"cell_type":"markdown","source":"## Classement avec modèles linéaires et perceptrons multicouches\n\nVoyons maintenant comment les notions de sur-apprentissage et sous-apprentissage peuvent se manifester dans le cas d’un problème de\nclassement (ou classification). Nous examinerons un problème simple de discrimination entre deux classes, similaire à celui illustré dans le\nsupport de cours.\n\nNous générons des données à partir de lois normales bidimensionnelles. Pour la première classe nous employons une seule loi avec des variances\ndifférentes et une rotation qui introduit des covariances. La seconde classe est un mélange de 4 lois normales avec des centres différents.","metadata":{},"id":"e8dbb60e"},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n# fixer la graine aléatoire de numpy permet d'obtenir systématiquement les mêmes résultats\nnp.random.seed(150)\n\nfrom sklearn import datasets\n\ndataset = \"gaussian\"\n\nif dataset == \"gaussian\":\n    # définir matrices de rotation et de dilatation\n    rot = np.array([[0.94, -0.34], [0.34, 0.94]])\n    sca = np.array([[3.4, 0], [0, 2]])\n    # générer données classe 1\n    c1d = (np.random.randn(100,2)).dot(sca).dot(rot)\n\n    # générer données classe 2\n    c2d1 = np.random.randn(25,2)+[-10, 2]\n    c2d2 = np.random.randn(25,2)+[-7, -2]\n    c2d3 = np.random.randn(25,2)+[-2, -6]\n    c2d4 = np.random.randn(25,2)+[5, -7]\n\n    data = np.concatenate((c1d, c2d1, c2d2, c2d3, c2d4))\n\n    # générer étiquettes de classe\n    l1c = np.ones(100, dtype=int)\n    l2c = np.zeros(100, dtype=int)\n    labels = np.concatenate((l1c, l2c))\nelif dataset == \"iris\":\n    iris_X, iris_y = datasets.load_iris(return_X_y=True)\n    data = iris_X[:, :2]\n    labels = iris_y\nelif dataset == \"wine\":\n    wine_X, wine_y = datasets.load_wine(return_X_y=True)\n    data = wine_X[:, (0,10)]\n    labels = wine_y","metadata":{"hide-output":false},"execution_count":null,"outputs":[],"id":"4005cf51"},{"cell_type":"markdown","source":"Visualisation de toutes les données :","metadata":{},"id":"47310a8f"},{"cell_type":"code","source":"# les échantillons du premier groupe sont en rouge 'r', ceux du deuxième groupe en vert (\"green\") 'g'\ncmp = np.array(['r','g', 'b'])\nplt.figure(figsize=(8, 6))\nplt.scatter(data[:,0],data[:,1], c=cmp[labels], s=50, edgecolors='none')\nplt.show()","metadata":{"hide-output":false},"execution_count":null,"outputs":[],"id":"8001f6dd"},{"cell_type":"markdown","source":"Nous générons maintenant un premier découpage entre données d’apprentissage et données de test. Les données de test sont affichées\navec cercles vides (`c='none'`), les données d’apprentissage avec des cercles remplis.","metadata":{},"id":"5aadecb7"},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# découpage des données en train et test\nX_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.33, random_state=0)\n\nplt.figure(figsize=(8, 6))\nplt.scatter(X_train[:,0],X_train[:,1],c=cmp[y_train], s=50, edgecolors='none', label=\"Exemples d'apprentissage\")\nplt.scatter(X_test[:,0], X_test[:,1], c='none' ,s=50, edgecolors=cmp[y_test], label=\"Exemples de test\")\nplt.legend()\nplt.show()","metadata":{"hide-output":false},"execution_count":null,"outputs":[],"id":"c7676dab"},{"cell_type":"markdown","source":"## Question\n\nCombien d’échantillons le jeu de données d’apprentissage contient-il ? La [documentation de scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\npeut vous aider.","metadata":{},"id":"f890baee"},{"cell_type":"markdown","source":"## Correction\n\nLe paramètre test_size=0.33 signifie que l’on conserve 33% des données pour le jeu de test. Le jeu d’apprentissage contient donc 67% des observations, soit 134 échantillons (le jeu de données gaussien contient 200 exemples).","metadata":{},"id":"e05cbb10"},{"cell_type":"markdown","source":"### Modèle linéaire : AFD\n\nNous cherchons d’abord un modèle linéaire pour ce problème de discrimination entre deux classes et utilisons pour cela l’étape\ndécisionnelle de l’analyse factorielle discriminante (AFD). En résumé, cette méthode cherche la frontière de décision linéaire qui sépare au\nmieux les données en maximisant la variance entre les barycentres des deux groupes. Pour plus de détails, vous pouvez consulter [la\ndocumentation de l’AFD dans scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html)\nainsi que le chapitre et les travaux pratiques de l”[UE RCP208](https://cedric.cnam.fr/vertigo/Cours/ml/tpAfd.html)) portant sur les méthodes factorielles.","metadata":{},"id":"3115b0e2"},{"cell_type":"code","source":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nlda = LinearDiscriminantAnalysis()\n\n# évaluation et affichage sur split1\nlda.fit(X_train, y_train)\nprint(\"Le score sur le jeu d'apprentissage est de : {:.3f}\".format(lda.score(X_train, y_train)))\n\nprint(\"Le score sur le jeu de test est de : {:.3f}\".format(lda.score(X_test, y_test)))","metadata":{"hide-output":false},"execution_count":null,"outputs":[],"id":"ab7dc527"},{"cell_type":"markdown","source":"Nous pouvons examiner visuellement le modèle trouvé (la frontière de\ndiscrimination linéaire, c’est-à-dire ici une droite dans le plan) :","metadata":{},"id":"ada96b87"},{"cell_type":"code","source":"# on créé une nouvelle figure sur laquelle on affiche les points\nplt.figure(figsize=(8, 6))\nplt.scatter(X_train[:,0], X_train[:,1], c=cmp[y_train], s=50, edgecolors='none', label=\"Train\")\nplt.scatter(X_test[:,0],  X_test[:,1], c='none', s=50, edgecolors=cmp[y_test], label=\"Test\")\n\n# on calcule pour chaque point du plan sa probabilité d'appartenir à chaque classe\nnx, ny = 400, 400\nx_min, x_max = plt.xlim()\ny_min, y_max = plt.ylim()\n# meshgrid permet d'échantillonner tous les points du plan (entre x_min et x_max)\nxx, yy = np.meshgrid(np.linspace(x_min, x_max, nx),np.linspace(y_min, y_max, ny))\n# .predict_proba permet de prédire le score de la LDA pour un ensemble d'observations\nZ = lda.predict_proba(np.c_[xx.ravel(), yy.ravel()])\nfor cls_idx in range(max(labels)):\n    zz = Z[:, cls_idx].reshape(xx.shape)\n    # on dessine la frontière correspond à un score de 0,5\n    # les scores < 0,5 correspondent à la classe 0\n    # les scores > 0,5 correspondent à la classe 1\n    plt.contour(xx, yy, zz, [0.5])\nplt.legend()\nplt.show()","metadata":{"hide-output":false},"execution_count":null,"outputs":[],"id":"d692750c"},{"cell_type":"markdown","source":"### Modèle non-linéaire: perceptron multicouche\n\nComme vous avez pu le constater, la frontière de séparation idéale entre les deux groupes n’est pas linéaire. Il nous faut donc changer de\nfamille paramétrique pour en choisir une de plus grande capacité. Nous allons donc utiliser un réseau de neurones simple (un perceptron multicouche) pour réaliser la discrimination binaire. Nous utilisons\npour cela la classe [MLPClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)\nde scikit-learn (voir aussi [ces explications](http://scikit-learn.org/stable/modules/neural_networks_supervised.html#classification) concernant le fonctionnement général de cet objet). Il est très\ninstructif d’examiner [les valeurs par défaut des paramètres](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier).\n\nLes perceptrons multicouches ont été présentés dans [le dernier chapitre de l’UE RCP208](https://cedric.cnam.fr/vertigo/Cours/ml/coursReseauxNeuronesMulticouches.html)\nportant sur les réseaux de neurones. Il n’est pas indispensable de connaître le fonctionnement précis des réseaux de neurones pour ce TP, ces modèles seront revus par la suite dans la partie du cours portant\nsur l’apprentissage profond.\n\nLes trois paramètres importants que nous allons manipuler sont le coefficient d’oubli, le nombre de neurones par couche et le nombre de couches. Par défaut, scikit-learn instancie un réseau de neurones à une\nseule couche cachée contenant 100 neurones.\n\nNous utilisons d’abord un coefficient « d’oubli » (*weight decay*) `alpha = 1e-5`. Ce terme correspond à l’intensité de la régularisation L2 appliquée sur le perceptron. Pour rappel, l’objectif de la\nrégularisation est de réduire la capacité du modèle.","metadata":{},"id":"18381ecf"},{"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\n# nous utilisons ici l'algorithme L-BFGS pour optimiser le perceptron\nclf = MLPClassifier(solver='lbfgs', alpha=1e-5, max_iter=1000, random_state=42)\n\n# évaluation et affichage sur split1\nclf.fit(X_train, y_train)\ntrain_score = clf.score(X_train, y_train)\nprint(f\"Le score en train est {train_score:.3f}\")\n\ntest_score = clf.score(X_test, y_test)\nprint(f\"Le score en test est {test_score:.3f}\")","metadata":{"hide-output":false},"execution_count":null,"outputs":[],"id":"616db92b"},{"cell_type":"markdown","source":"### Question\n\nÀ l’aide de la documentation de scikit-learn, déterminez à quoi correspond la valeur renvoyée par la méthode .score().","metadata":{},"id":"dfac1524"},{"cell_type":"markdown","source":"### Correction\n\n.score() calcule la métrique habituelle de classification: l”*accuracy* (en français, le taux de bonnes prédictions), c’est-à-dire le pourcentage d’exemples dont la classe a été correctement prédite par le modèle.\n\nComme précédemment pour l’analyse factorielle discriminante, nous pouvons désormais tracer la frontière de décision du perceptron multicouche que nous venons d’optimiser.","metadata":{},"id":"3f0c91c4"},{"cell_type":"code","source":"# créer une nouvelle figure\nplt.figure()\n# afficher les nuages de points apprentissage (remplis) et de test (vides)\nplt.scatter(X_train[:,0],X_train[:,1],c=cmp[y_train],s=50, edgecolors='none', label=\"Train\")\nplt.scatter(X_test[:,0], X_test[:,1], c='none', s=50, edgecolors=cmp[y_test], label=\"Test\")\n\n# calculer la probabilité de sortie du perceptron pour tous les points du plan\nnx, ny = 200, 200\nx_min, x_max = plt.xlim()\ny_min, y_max = plt.ylim()\nxx, yy = np.meshgrid(np.linspace(x_min, x_max, nx),np.linspace(y_min, y_max, ny))\nZ = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])\nfor cls_idx in range(max(labels)):\n    zz = Z[:, cls_idx].reshape(xx.shape)\n    # on dessine la frontière correspond à un score de 0,5\n    # les scores < 0,5 correspondent à la classe 0\n    # les scores > 0,5 correspondent à la classe 1\n    plt.contour(xx, yy, zz, [0.5])\nplt.legend()\nplt.show()","metadata":{"hide-output":false},"execution_count":null,"outputs":[],"id":"e8d30da4"},{"cell_type":"markdown","source":"### Question\n\nRefaites l’expérience avec `alpha = 1`. Dans quel cas la régularisation est plus forte ? Quelle est la conséquence sur les résultats ?","metadata":{},"id":"4755088b"},{"cell_type":"markdown","source":"### Correction\n\nLa régularisation est plus élevée lorsque `alpha=1`. La frontière est alors nettement moins irrégulière (on réduit la variance en diminuant la capacité du modèle).\n\nLa visualisation interactive ci-dessous permet de manipuler simultanément les trois paramètres importants que nous avons décrit précédemment : coefficient d’oubli, nombre de couches, nombre de\nneurones par couche. Dans le perceptron, les paramètres à optimiser sont les poids des connexions entre les neurones. Plus il y a de couches et plus il y a de neurones dans une couche, plus le nombre de connexions est élevé (et par conséquent plus il y a de paramètres).","metadata":{},"id":"9b0bfc9c"},{"cell_type":"code","source":"import ipywidgets as widgets\n\n@interact(alpha=widgets.FloatLogSlider(value=1, base=10, min=-5, max=3, step=1),\n          neurons=(10, 200, 10),\n          layers=(1, 4, 1))\ndef mlp_fit(alpha, neurons, layers):\n    # nous utilisons ici l'algorithme L-BFGS pour optimiser le perceptron\n    layer_sizes = (neurons,) * layers\n    clf = MLPClassifier(solver='lbfgs', alpha=alpha, hidden_layer_sizes=layer_sizes, max_iter=1000, tol=1e-3, random_state=0)\n\n    # évaluation et affichage sur split1\n    clf.fit(X_train, y_train)\n    train_score = clf.score(X_train, y_train)\n    print(f\"Le score en train est {train_score:.3f}\")\n\n    test_score = clf.score(X_test, y_test)\n    print(f\"Le score en test est {test_score:.3f}\")\n\n    # on créé une nouvelle figure sur laquelle on affiche les points\n    plt.figure(figsize=(8, 6))\n    plt.scatter(X_train[:,0], X_train[:,1], c=cmp[y_train], s=50, edgecolors='none', label=\"Train\")\n    plt.scatter(X_test[:,0],  X_test[:,1], c='none', s=50, edgecolors=cmp[y_test], label=\"Test\")\n\n    # on calcule pour chaque point du plan sa probabilité d'appartenir à chaque classe\n    nx, ny = 400, 400\n    x_min, x_max = plt.xlim()\n    y_min, y_max = plt.ylim()\n    # meshgrid permet d'échantillonner tous les points du plan (entre x_min et x_max)\n    xx, yy = np.meshgrid(np.linspace(x_min, x_max, nx),np.linspace(y_min, y_max, ny))\n    # .predict_proba permet de prédire le score de chaque classe pour un ensemble d'observations\n    Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])\n    for cls_idx in range(max(labels)):\n        zz = Z[:, cls_idx].reshape(xx.shape)\n        # on dessine la frontière correspond à un score de 0,5\n        # les scores < 0,5 correspondent à la classe 0\n        # les scores > 0,5 correspondent à la classe 1\n        plt.contour(xx, yy, zz, [0.5])\n    plt.legend()\n    plt.show()","metadata":{"hide-output":false},"execution_count":null,"outputs":[],"id":"aed73073"},{"cell_type":"markdown","source":"### Question\n\nExpérimentez avec la visualisation ci-dessus. Que se passe-t-il lorsque le nombre de couches augmente ? Lorsque le nombre de neurones augmente ?\nComment pouvez-vous interpréter ces résultats du point de vue de la capacité du modèle, du sur-apprentissage et du sous-apprentissage ?","metadata":{},"id":"9c56ee75"},{"cell_type":"markdown","source":"### Correction\n\nAugmenter le nombre de couches ou le nombre de neurones revient à augmenter le nombre de paramètres du modèle: la capacité augmente et donc le sur-apprentissage également.\n\nLes résultats changent peu lorsque `alpha` est suffisamment élevé: la régularisation réduit artificiellement la capacité du modèle, même lorsque le nombre de paramètres augmente. C’est donc une façon de contrôler le sur-apprentissage, même pour un modèle de grande capacité.","metadata":{},"id":"9c7fc936"},{"cell_type":"markdown","source":"### Question\n\nGénérez d’autres découpages apprentissage/test en réexécutant la fonction `train_test_split` avec une autre valeur de graine aléatoire (`random_state=`).\nExaminez la variabilité des résultats lorsque ce découpage change. Dans quel cas elle est plus forte ?","metadata":{},"id":"be5990b1"},{"cell_type":"markdown","source":"### Correction\n\nLa variabilité des résultats selon le découpage apprentissage/test est plus forte lorsque le modèle est en sur-apprentissage (grand nombre de couches/neurones et alpha faible) : le modèle mémorise du bruit statistique lié à l’échantillonnage des données. Les frontières sont irrégulières et modélisent moins bien la frontière réelle.","metadata":{},"id":"efb1ec12"},{"cell_type":"markdown","source":"## Pour aller plus loin\n\nReprenez la deuxième partie du TP sur le problème de discrimination à l’aide d’un modèle linéaire (AFD) et d’un modèle non-linéaire (PMC) mais\nen changeant le jeu de données. Vous pouvez modifier la variable `dataset` par `\"wine\"` ou `\"iris\"` pour utiliser respectivement le\n*Wine Dateset* ou les Iris de Fisher.\n\nLe jeu de données *Wine Dataset* est une collection de 178 vins italiens répartis en 3 catégories, chacune correspondant à un vignoble différent.\nTreize mesures physico-chimiques sont disponibles mais dans ce TP nous n’utilisons que les deux premières (taux d’alcool et la couleur du vin).\nPlus de détails [ici](https://scikit-learn.org/stable/datasets/toy_dataset.html#wine-dataset).\n\nLes Iris de Fisher est un jeu de données célèbre en classification automatique. Il comporte 150 échantillons répartis en trois classes de\nfleurs (Iris Setosa, Iris Versicolour et Iris Virginica). Pour chaque plante, quatre caractéristiques végétales ont été mesurés : longueur\nsépale, largeur sépale, longueur de pétale, largeur de pétale. Dans ce TP nous n’utilisons que la longueur et la largeur sépale. Plus\nd’informations sur Iris [ici](https://scikit-learn.org/stable/datasets/toy_dataset.html#iris-dataset).","metadata":{},"id":"2b0b019a"}]}